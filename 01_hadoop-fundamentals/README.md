# Proyecto 01 – Fundamentos de Hadoop

Este proyecto está diseñado para entender los fundamentos del ecosistema Hadoop, sus componentes principales y cómo funciona el procesamiento distribuido en entornos Big Data.

## 🎯 Objetivos
- Comprender la arquitectura de Hadoop: HDFS, YARN, MapReduce.
- Simular el flujo de trabajo de un procesamiento de datos usando MapReduce.
- Ejecutar ejercicios prácticos (en local) que reproduzcan los conceptos aprendidos.

## 🧰 Herramientas utilizadas
- Jupyter Notebook
- Python (simulación del flujo MapReduce)
- Hadoop (simulación en local o en sandbox)
- Visualizaciones básicas

## 📄 Contenido
1. Explicación del ecosistema Hadoop y sus componentes.
2. Mini MapReduce con Python: contar palabras en un archivo grande.
3. Ejemplo de lectura y escritura en “HDFS simulado” usando carpetas.
4. Reflexión personal: ¿por qué Hadoop cambió la forma de trabajar con datos?

## 📁 Archivos incluidos
- `hadoop_intro.ipynb`: Código comentado con ejemplos de MapReduce y simulaciones.
- `/resultados/`: Capturas de salida y visualización de datos.

## 🔎 Resultados esperados
- Archivo de conteo de palabras.
- Capturas del flujo de datos simulado.
- Comprensión clara del funcionamiento básico de Hadoop.

---

✍️ Autor: Dachel Hernández  
📅 Fecha: [2025]
